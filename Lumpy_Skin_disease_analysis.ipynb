{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee3b94f-4652-42cb-a2cc-ea54b321ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = '/Users/saifalikhan/Python-Anaconda/Ph.D. Work/Lumpy/Lumpy_data_updated.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d75eb17-f633-4f4f-addf-f1f1f001cd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_case_counts = df.groupby('Country')['Diagnosis.status'].count().reset_index()\n",
    "\n",
    "country_case_counts = country_case_counts.rename(columns={'Diagnosis.status': 'Case Count'})\n",
    "\n",
    "top_12_countries = country_case_counts.sort_values(by='Case Count', ascending=False).head(10)\n",
    "\n",
    "top_12_countries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070e29d7-4e71-436a-905b-749206776659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.dates import DateFormatter\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# Filter the dataset for only the top 12 countries\n",
    "top_countries = top_12_countries['Country'].tolist()\n",
    "filtered_df = df[df['Country'].isin(top_countries)]\n",
    "\n",
    "# Convert the 'report_date' column to datetime format for proper time series plotting\n",
    "filtered_df['Reporting Date'] = pd.to_datetime(filtered_df['Reporting Date'])\n",
    "\n",
    "# Group by Country and report_date to get the daily case counts\n",
    "time_series_data = (\n",
    "    filtered_df.groupby(['Country', 'Reporting Date'])\n",
    "    .size()\n",
    "    .reset_index(name='Case Count')\n",
    ")\n",
    "\n",
    "# Create subplots (3 rows x 4 columns)\n",
    "fig, axes = plt.subplots(5, 2, figsize=(20, 12))  # Removed `sharex=True` for independent x-axis ranges\n",
    "axes = axes.flatten()  # Flatten the 3x4 grid into a 1D array for easy iteration\n",
    "\n",
    "\n",
    "for idx, country in enumerate(top_countries):\n",
    "    ax = axes[idx]\n",
    "    country_data = time_series_data[time_series_data['Country'] == country]\n",
    "    \n",
    "    sns.lineplot(\n",
    "        data=country_data,\n",
    "        x='Reporting Date',\n",
    "        y='Case Count',\n",
    "        ax=ax,\n",
    "        #color=custom_palette[idx]  # Assign a unique color for each country\n",
    "    )\n",
    "    \n",
    "    ax.xaxis.set_major_formatter(DateFormatter(\"%Y-%m\"))\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(5))  # Ensure only 5 ticks are shown on the x-axis\n",
    "\n",
    "    ax.set_title(country, fontsize=14, fontweight = 'bold')\n",
    "    ax.set_xlabel(\"Timespan\", fontsize=12, fontweight = 'bold')\n",
    "    ax.set_ylabel(\"Case Count\", fontsize=12, fontweight = 'bold')\n",
    "\n",
    "for i in range(len(top_countries), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "# Save the combined figure with bbox_to_anchor legend properly included\n",
    "plt.savefig('trend_lumpy_data_by_country.png', dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a4b68-b9b3-4f24-b7dd-d16e13b805a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame to store ADF test results\n",
    "adf_results = []\n",
    "\n",
    "fig, axs = plt.subplots(10, 2, figsize=(15, 15))  # 10x2 grid for ACF and PACF\n",
    "axs = axs.reshape(10, 2)  # Ensure it is reshaped to (10, 2)\n",
    "\n",
    "for idx, country in enumerate(top_countries[:10]):  # Only top 10 countries\n",
    "    country_data = time_series_data[time_series_data['Country'] == country]\n",
    "    \n",
    "    daily_cases = country_data.groupby('Reporting Date')['Case Count'].sum()\n",
    "    \n",
    "    # ADF test results\n",
    "    adf_result = adfuller(daily_cases)\n",
    "    stationary = adf_result[1] < 0.05  # If p-value < 0.05, the series is stationary\n",
    "    \n",
    "    adf_results.append({\n",
    "        'Country': country,\n",
    "        'ADF Statistic': adf_result[0],\n",
    "        'p-value': adf_result[1],\n",
    "        'Stationary': 'Yes' if stationary else 'No'\n",
    "    })\n",
    "    \n",
    "    max_lags = max(1, len(daily_cases) // 2 - 1)  # Ensure at least 1 lag and up to half of the data points\n",
    "    \n",
    "    plot_acf(daily_cases, ax=axs[idx, 0], lags=max_lags)\n",
    "    plot_pacf(daily_cases, ax=axs[idx, 1], lags=max_lags)\n",
    "    \n",
    "    axs[idx, 0].set_title(f'{country} ACF', fontsize=12, fontweight = 'bold')\n",
    "    axs[idx, 1].set_title(f'{country} PACF', fontsize=12, fontweight = 'bold')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "adf_results_df = pd.DataFrame(adf_results)\n",
    "plt.savefig('ACF_PACF.png', dpi=500)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a7d957-4052-453c-aadc-15c2d1f20ea1",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6091f940-622b-429e-88a3-fb8f2efc40c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def train_predict_autoarima(train_data, test_data):\n",
    "    model = auto_arima(train_data, seasonal=True, suppress_warnings=True, stepwise=True, error_action='ignore', max_d=2)\n",
    "    forecast = model.predict(n_periods=len(test_data))\n",
    "    mse = mean_squared_error(test_data, forecast)\n",
    "    return forecast, mse\n",
    "\n",
    "def train_predict_decision_tree(X_train, y_train, X_test):\n",
    "    model = DecisionTreeRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    forecast = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, forecast)  # Assuming y_test is available globally\n",
    "    return forecast, mse\n",
    "\n",
    "def train_predict_random_forest(X_train, y_train, X_test):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    forecast = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, forecast)  # Assuming y_test is available globally\n",
    "    return forecast, mse\n",
    "\n",
    "def train_predict_svr(X_train, y_train, X_test):\n",
    "    model = SVR(kernel='rbf', C=100, gamma='scale')\n",
    "    model.fit(X_train, y_train)\n",
    "    forecast = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, forecast)  # Assuming y_test is available globally\n",
    "    return forecast, mse\n",
    "\n",
    "def plot_results(ax, train_data, test_data, forecast, title):\n",
    "    combined_data = pd.concat([train_data, test_data])\n",
    "    \n",
    "    ax.plot(combined_data.index, combined_data.values, label='Actual', color='blue', linestyle='--')\n",
    "    \n",
    "    ax.plot(train_data.index, train_data.values, label='Train', color='blue', linestyle='--')\n",
    "    ax.plot(test_data.index, test_data.values, label='Test', color='orange', linestyle='--')\n",
    "    \n",
    "    ax.plot(test_data.index, forecast, label='Forecast', color='green')\n",
    "    \n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    ax.set_xlabel('Date', fontweight='bold')\n",
    "    ax.set_ylabel('Lumpy Cases', fontweight='bold')\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(nbins=4))\n",
    "    ax.tick_params(axis='x', rotation=0)\n",
    "    return ax\n",
    "\n",
    "df = pd.read_excel('/Users/saifalikhan/Python-Anaconda/Ph.D. Work/Lumpy/Lumpy_data_updated.xlsx', parse_dates=['Reporting Date'])\n",
    "\n",
    "top_countries = df.groupby('Country')['Diagnosis.status'].sum().nlargest(10).index\n",
    "\n",
    "combined_results = []\n",
    "\n",
    "fig, axs = plt.subplots(10, 4, figsize=(20, 18), dpi=500)\n",
    "axs = axs.flatten()\n",
    "\n",
    "models = ['AutoARIMA', 'Decision Tree', 'Random Forest', 'SVR']\n",
    "model_functions = [train_predict_autoarima, train_predict_decision_tree, train_predict_random_forest, train_predict_svr]\n",
    "\n",
    "train_lines = []\n",
    "test_lines = []\n",
    "forecast_lines = []\n",
    "\n",
    "for i, country in enumerate(top_countries):\n",
    "    country_data = df[df['Country'] == country]\n",
    "    country_data = country_data.sort_values('Reporting Date')\n",
    "    \n",
    "    daily_cases = country_data.groupby('Reporting Date')['Diagnosis.status'].sum()\n",
    "    \n",
    "    lags = 5\n",
    "    data = pd.DataFrame({'y': daily_cases})\n",
    "    for lag in range(1, lags + 1):\n",
    "        data[f'lag_{lag}'] = data['y'].shift(lag)\n",
    "    data = data.dropna()\n",
    "    \n",
    "    X = data.drop(columns=['y'])\n",
    "    y = data['y']\n",
    "    train_size = int(0.8 * len(data))\n",
    "    X_train, X_test, y_train, y_test = X.iloc[:train_size], X.iloc[train_size:], y.iloc[:train_size], y.iloc[train_size:]\n",
    "    \n",
    "    try:\n",
    "        for j, (model_name, model_func) in enumerate(zip(models, model_functions)):\n",
    "            if model_name == 'AutoARIMA':\n",
    "                forecast, mse = model_func(y_train, y_test)\n",
    "            else:\n",
    "                forecast, mse = model_func(X_train, y_train, X_test)\n",
    "            \n",
    "            plot_results(axs[i * len(models) + j], y_train, y_test, forecast, f'{country} - {model_name}')\n",
    "            \n",
    "            combined_results.append({\n",
    "                'Country': country,\n",
    "                'Model': model_name,\n",
    "                'MSE': mse,\n",
    "                'Forecast': forecast.tolist()\n",
    "            })\n",
    "            \n",
    "            # Collect lines for legend\n",
    "            if i == 0 and j == 0:\n",
    "                train_lines.append(axs[i * len(models) + j].lines[1])  # Train line\n",
    "                test_lines.append(axs[i * len(models) + j].lines[2])   # Test line\n",
    "                forecast_lines.append(axs[i * len(models) + j].lines[3])  # Forecast line\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while processing {country}: {e}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.legend(handles=[train_lines[0], test_lines[0], forecast_lines[0]], labels=['Train', 'Test', 'Forecast'],\n",
    "           loc='upper right', bbox_to_anchor=(1.04, 0.98), fontsize='large')\n",
    "\n",
    "\n",
    "combined_results_df = pd.DataFrame(combined_results)\n",
    "#combined_results_df.to_excel(\"combined_results.xlsx\", index=False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094329d9-cd85-46e1-8edc-6c516d247a69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27009c7-c30b-4c24-8bbf-0e4738979a13",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c24de-39a5-4eef-b865-6370c0f08ac7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# AutoARIMA forecast\n",
    "def train_predict_autoarima(train_data, test_data):\n",
    "    model = auto_arima(train_data, seasonal=True, suppress_warnings=True, stepwise=True, error_action='ignore', max_d=2)\n",
    "    forecast = model.predict(n_periods=len(test_data))\n",
    "    mse = mean_squared_error(test_data, forecast)\n",
    "    return forecast, mse\n",
    "\n",
    "# Decision Tree with fixed hyperparameters\n",
    "def train_predict_decision_tree(X_train, y_train, X_test, y_test):\n",
    "    param_grid = {\n",
    "        'max_depth': [3, 5, 10, None],\n",
    "        'min_samples_leaf': [1, 2, 4, 6]\n",
    "    }\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    dt = DecisionTreeRegressor(random_state=42)\n",
    "    grid_search = GridSearchCV(dt, param_grid, cv=tscv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    print(f\"Best Decision Tree params: {grid_search.best_params_}\")\n",
    "\n",
    "    forecast = best_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, forecast)\n",
    "    return forecast, mse\n",
    "\n",
    "\n",
    "# Random Forest with hyperparameter tuning using time series CV\n",
    "def train_predict_random_forest(X_train, y_train, X_test, y_test):\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 10, None],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    grid_search = GridSearchCV(rf, param_grid, cv=tscv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    print(f\"Best Random Forest params: {grid_search.best_params_}\")\n",
    "    \n",
    "    forecast = best_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, forecast)\n",
    "    return forecast, mse\n",
    "\n",
    "# SVR\n",
    "def train_predict_svr(X_train, y_train, X_test, y_test):\n",
    "    model = SVR(kernel='rbf', C=100, gamma='scale')\n",
    "    model.fit(X_train, y_train)\n",
    "    forecast = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, forecast)\n",
    "    return forecast, mse\n",
    "\n",
    "# Plotting\n",
    "def plot_results(ax, train_data, test_data, forecast, title):\n",
    "    combined_data = pd.concat([train_data, test_data])\n",
    "    ax.plot(combined_data.index, combined_data.values, label='Actual', color='blue', linestyle='--')\n",
    "    ax.plot(train_data.index, train_data.values, label='Train', color='blue', linestyle='--')\n",
    "    ax.plot(test_data.index, test_data.values, label='Test', color='orange', linestyle='--')\n",
    "    ax.plot(test_data.index, forecast, label='Forecast', color='green')\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    ax.set_xlabel('Date', fontweight='bold')\n",
    "    ax.set_ylabel('Lumpy Cases', fontweight='bold')\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(nbins=4))\n",
    "    ax.tick_params(axis='x', rotation=0)\n",
    "    return ax\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel('/Users/saifalikhan/Python-Anaconda/Ph.D. Work/Lumpy/Lumpy_data_updated.xlsx', parse_dates=['Reporting Date'])\n",
    "\n",
    "# Get top 10 countries by cases\n",
    "top_countries = df.groupby('Country')['Diagnosis.status'].sum().nlargest(10).index\n",
    "\n",
    "# Results and figure\n",
    "combined_results = []\n",
    "fig, axs = plt.subplots(10, 4, figsize=(20, 18), dpi=500)\n",
    "axs = axs.flatten()\n",
    "\n",
    "models = ['AutoARIMA', 'Decision Tree', 'Random Forest', 'SVR']\n",
    "model_functions = [\n",
    "    lambda yt, yv, *_: train_predict_autoarima(yt, yv),\n",
    "    train_predict_decision_tree,\n",
    "    train_predict_random_forest,\n",
    "    train_predict_svr\n",
    "]\n",
    "\n",
    "train_lines, test_lines, forecast_lines = [], [], []\n",
    "\n",
    "for i, country in enumerate(top_countries):\n",
    "    country_data = df[df['Country'] == country].sort_values('Reporting Date')\n",
    "    daily_cases = country_data.groupby('Reporting Date')['Diagnosis.status'].sum()\n",
    "    \n",
    "    lags = 5\n",
    "    data = pd.DataFrame({'y': daily_cases})\n",
    "    for lag in range(1, lags + 1):\n",
    "        data[f'lag_{lag}'] = data['y'].shift(lag)\n",
    "    data = data.dropna()\n",
    "\n",
    "    X = data.drop(columns=['y'])\n",
    "    y = data['y']\n",
    "    train_size = int(0.8 * len(data))\n",
    "    X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]\n",
    "    y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n",
    "\n",
    "    try:\n",
    "        for j, (model_name, model_func) in enumerate(zip(models, model_functions)):\n",
    "            if model_name == 'AutoARIMA':\n",
    "                forecast, mse = model_func(y_train, y_test)\n",
    "            else:\n",
    "                forecast, mse = model_func(X_train, y_train, X_test, y_test)\n",
    "            \n",
    "            plot_results(axs[i * len(models) + j], y_train, y_test, forecast, f'{country} - {model_name}')\n",
    "            combined_results.append({\n",
    "                'Country': country,\n",
    "                'Model': model_name,\n",
    "                'MSE': mse,\n",
    "                'Forecast': forecast.tolist()\n",
    "            })\n",
    "\n",
    "            if i == 0 and j == 0:\n",
    "                train_lines.append(axs[i * len(models) + j].lines[1])\n",
    "                test_lines.append(axs[i * len(models) + j].lines[2])\n",
    "                forecast_lines.append(axs[i * len(models) + j].lines[3])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {country} with {model_name}: {e}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.legend(handles=[train_lines[0], test_lines[0], forecast_lines[0]], labels=['Train', 'Test', 'Forecast'],\n",
    "           loc='upper right', bbox_to_anchor=(1.04, 0.98), fontsize='large')\n",
    "\n",
    "# Save if needed\n",
    "#plt.savefig('combined_forecast_plots.png', bbox_inches='tight', dpi=500)\n",
    "#plt.savefig('combined_forecast_plots.pdf', bbox_inches='tight', dpi=500)\n",
    "\n",
    "combined_results_df = pd.DataFrame(combined_results)\n",
    "#combined_results_df.to_excel(\"combined_results.xlsx\", index=False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22eafbb-edb4-4402-a655-beb6d61e85dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f88260e-3d4c-46bb-ab97-9a0e895e2534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
